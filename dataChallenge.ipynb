{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime \n",
    "from scipy.stats import lognorm, zscore, linregress\n",
    "%matplotlib inline \n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import csv file\n",
    "df=pd.read_csv('crap.csv', header=0)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and Statistical Modeling Questions\n",
    "\n",
    "#### 1. i. For the data set, identify high price outliers. Explain how you identified these outliers.\n",
    "\n",
    "1.1 Outlier Detection\n",
    "   Two cases come to mind:\n",
    "       a) An input error by the contributor. This may an incorrect placement of a decimal point (i.e. quantity=1.00 -> quantity=100.).  The mistake can happen while inputing the price, quantity, size, units. Each of these contribute to the normalized price which will we use to find the outliers. \n",
    "       b) Given that contributors are financially compensated for the contributions, fraudulent submissions are innevitble. This often leads to a cat-and-mouse situation and the outlier algorithm needs to be updated\n",
    "       \n",
    "1.2 Not quite guassian Log-Normal plot(?):\n",
    "    Giving that we do not expect prices to go below 0 and that decimal point mistakes can change the price values by order of magnitudes above and below the real price, a guassian distribution may not be suitable to model prices. On the otherhand, the log of the prices could follow a normal distributions so we use that.     \n",
    "    \n",
    "1.3 Method:\n",
    "    After transforming the normalized price column to Log(normalized price), we define an outlier as a data point likes beyond 3 sigma of the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Empty dataframe to fill later\n",
    "outliers = pd.DataFrame()\n",
    "\n",
    "#Create dataframes who's content has ben grouped by Product\n",
    "groupedDf = df.groupby([\"p_item_product_lc\"])\n",
    "\n",
    "\n",
    "for prod_place, gp in groupedDf:\n",
    "    #Add column of Log(normalized prices)\n",
    "    gp.loc[:,'log_normalized_price'] = gp['normalized_price'].apply(lambda x: np.log(x))\n",
    "    \n",
    "    #Calculate z-score\n",
    "    gp.loc[:,'zScore']= zscore(gp['log_normalized_price'])\n",
    "    \n",
    "    #store datapoints at least 1.96 sigma away\n",
    "    z = gp[np.abs(gp[\"zScore\"])>1.96]\n",
    "\n",
    "    if not z.empty : \n",
    "        outliers = outliers.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_time</th>\n",
       "      <th>p_item_manufacturer_lc</th>\n",
       "      <th>p_item_brand_lc</th>\n",
       "      <th>p_item_sub_brand_lc</th>\n",
       "      <th>p_item_product_lc</th>\n",
       "      <th>p_item_description_lc</th>\n",
       "      <th>p_item_uuid</th>\n",
       "      <th>packaging</th>\n",
       "      <th>p_quantity</th>\n",
       "      <th>p_size</th>\n",
       "      <th>...</th>\n",
       "      <th>t_created</th>\n",
       "      <th>t_modified</th>\n",
       "      <th>t_uploaded_lc</th>\n",
       "      <th>g_timezone</th>\n",
       "      <th>g_source</th>\n",
       "      <th>thumbnail_0x0</th>\n",
       "      <th>thumbnail_300x300</th>\n",
       "      <th>u_uuid</th>\n",
       "      <th>log_normalized_price</th>\n",
       "      <th>zScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94603</th>\n",
       "      <td>2015-01-08 10:48:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spec:6877309b-f6c3-4073-853f-ff2652dcd1d8</td>\n",
       "      <td>per pcs.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-01-08 10:48:49</td>\n",
       "      <td>2015-01-12 20:38:06.577000</td>\n",
       "      <td>2015-01-08 10:48:49</td>\n",
       "      <td>Etc/GMT-0</td>\n",
       "      <td>offline</td>\n",
       "      <td>https://img.premise.com/0x0/a59542d8a005309636...</td>\n",
       "      <td>https://img.premise.com/300x300/a59542d8a00530...</td>\n",
       "      <td>e1f3044a-8703-4466-b043-1a383a518a86</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>3.792949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94714</th>\n",
       "      <td>2015-01-26 18:37:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spec:6877309b-f6c3-4073-853f-ff2652dcd1d8</td>\n",
       "      <td>per pcs.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-01-26 18:37:14</td>\n",
       "      <td>2015-01-27 17:59:08.533000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offline</td>\n",
       "      <td>https://img.premise.com/0x0/1bf3b3c9e514792852...</td>\n",
       "      <td>https://img.premise.com/300x300/1bf3b3c9e51479...</td>\n",
       "      <td>2132aed4-d164-464c-b5e5-85734f57f5ca</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>2.365355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94756</th>\n",
       "      <td>2015-01-30 16:04:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spec:6877309b-f6c3-4073-853f-ff2652dcd1d8</td>\n",
       "      <td>per pcs.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-01-30 16:04:40</td>\n",
       "      <td>2015-01-31 01:24:06.443000</td>\n",
       "      <td>2015-01-30 16:04:40</td>\n",
       "      <td>Etc/GMT+0</td>\n",
       "      <td>offline</td>\n",
       "      <td>https://img.premise.com/0x0/eb893a58a232e3a0c4...</td>\n",
       "      <td>https://img.premise.com/300x300/eb893a58a232e3...</td>\n",
       "      <td>9a92e2f6-c752-4521-bf82-8ae2da985dc9</td>\n",
       "      <td>-3.218876</td>\n",
       "      <td>-3.327078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94768</th>\n",
       "      <td>2015-02-02 10:55:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spec:6877309b-f6c3-4073-853f-ff2652dcd1d8</td>\n",
       "      <td>per pcs.</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-02-02 10:55:10</td>\n",
       "      <td>2015-02-02 23:51:23.471000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offline</td>\n",
       "      <td>https://img.premise.com/0x0/ce5075c7fbb2f27ffb...</td>\n",
       "      <td>https://img.premise.com/300x300/ce5075c7fbb2f2...</td>\n",
       "      <td>bf494e87-79e5-40f9-bd99-41e449dc359b</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>2.365355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94800</th>\n",
       "      <td>2015-02-03 12:34:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spec:6877309b-f6c3-4073-853f-ff2652dcd1d8</td>\n",
       "      <td>per pcs.</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-02-03 12:34:28</td>\n",
       "      <td>2015-02-04 01:53:24.633000</td>\n",
       "      <td>2015-02-03 12:34:28</td>\n",
       "      <td>Etc/GMT+0</td>\n",
       "      <td>offline</td>\n",
       "      <td>https://img.premise.com/0x0/5523082f112fb5a948...</td>\n",
       "      <td>https://img.premise.com/300x300/5523082f112fb5...</td>\n",
       "      <td>555446cf-385b-4228-a124-5da8a6bbfbe9</td>\n",
       "      <td>-2.639057</td>\n",
       "      <td>-2.153919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    t_time  p_item_manufacturer_lc p_item_brand_lc  \\\n",
       "94603  2015-01-08 10:48:49                     NaN             NaN   \n",
       "94714  2015-01-26 18:37:14                     NaN             NaN   \n",
       "94756  2015-01-30 16:04:40                     NaN             NaN   \n",
       "94768  2015-02-02 10:55:10                     NaN             NaN   \n",
       "94800  2015-02-03 12:34:28                     NaN             NaN   \n",
       "\n",
       "       p_item_sub_brand_lc p_item_product_lc  p_item_description_lc  \\\n",
       "94603                  NaN            Banana                    NaN   \n",
       "94714                  NaN            Banana                    NaN   \n",
       "94756                  NaN            Banana                    NaN   \n",
       "94768                  NaN            Banana                    NaN   \n",
       "94800                  NaN            Banana                    NaN   \n",
       "\n",
       "                                     p_item_uuid packaging  p_quantity  \\\n",
       "94603  spec:6877309b-f6c3-4073-853f-ff2652dcd1d8  per pcs.           1   \n",
       "94714  spec:6877309b-f6c3-4073-853f-ff2652dcd1d8  per pcs.           3   \n",
       "94756  spec:6877309b-f6c3-4073-853f-ff2652dcd1d8  per pcs.           5   \n",
       "94768  spec:6877309b-f6c3-4073-853f-ff2652dcd1d8  per pcs.           1   \n",
       "94800  spec:6877309b-f6c3-4073-853f-ff2652dcd1d8  per pcs.           1   \n",
       "\n",
       "       p_size    ...               t_created                  t_modified  \\\n",
       "94603       1    ...     2015-01-08 10:48:49  2015-01-12 20:38:06.577000   \n",
       "94714       1    ...     2015-01-26 18:37:14  2015-01-27 17:59:08.533000   \n",
       "94756       5    ...     2015-01-30 16:04:40  2015-01-31 01:24:06.443000   \n",
       "94768      12    ...     2015-02-02 10:55:10  2015-02-02 23:51:23.471000   \n",
       "94800       7    ...     2015-02-03 12:34:28  2015-02-04 01:53:24.633000   \n",
       "\n",
       "             t_uploaded_lc g_timezone g_source  \\\n",
       "94603  2015-01-08 10:48:49  Etc/GMT-0  offline   \n",
       "94714                  NaN        NaN  offline   \n",
       "94756  2015-01-30 16:04:40  Etc/GMT+0  offline   \n",
       "94768                  NaN        NaN  offline   \n",
       "94800  2015-02-03 12:34:28  Etc/GMT+0  offline   \n",
       "\n",
       "                                           thumbnail_0x0  \\\n",
       "94603  https://img.premise.com/0x0/a59542d8a005309636...   \n",
       "94714  https://img.premise.com/0x0/1bf3b3c9e514792852...   \n",
       "94756  https://img.premise.com/0x0/eb893a58a232e3a0c4...   \n",
       "94768  https://img.premise.com/0x0/ce5075c7fbb2f27ffb...   \n",
       "94800  https://img.premise.com/0x0/5523082f112fb5a948...   \n",
       "\n",
       "                                       thumbnail_300x300  \\\n",
       "94603  https://img.premise.com/300x300/a59542d8a00530...   \n",
       "94714  https://img.premise.com/300x300/1bf3b3c9e51479...   \n",
       "94756  https://img.premise.com/300x300/eb893a58a232e3...   \n",
       "94768  https://img.premise.com/300x300/ce5075c7fbb2f2...   \n",
       "94800  https://img.premise.com/300x300/5523082f112fb5...   \n",
       "\n",
       "                                     u_uuid log_normalized_price    zScore  \n",
       "94603  e1f3044a-8703-4466-b043-1a383a518a86             0.300105  3.792949  \n",
       "94714  2132aed4-d164-464c-b5e5-85734f57f5ca            -0.405465  2.365355  \n",
       "94756  9a92e2f6-c752-4521-bf82-8ae2da985dc9            -3.218876 -3.327078  \n",
       "94768  bf494e87-79e5-40f9-bd99-41e449dc359b            -0.405465  2.365355  \n",
       "94800  555446cf-385b-4228-a124-5da8a6bbfbe9            -2.639057 -2.153919  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display all outliers by product\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed many Fruit Juice observations have a z score above ten.  Investingating a bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select Fruit Juice\n",
    "fruitJuice = df[df[\"p_item_product_lc\"]==\"Fruit juice\"]\n",
    "#Plot all Fruit Juice normalized prices\n",
    "fruitJuice.ix[:,\"normalized_price\"].plot(kind=\"hist\",bins=100, logy=True, title=\"Normalized Fruit Juice Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fruitJuiceOutliers= outliers[outliers[\"p_item_product_lc\"]==\"Fruit juice\"]\n",
    "for contributor in fruitJuiceOutliers.groupby(\"u_uuid\"):\n",
    "    contributor[1].loc[:,\"normalized_price\"].plot(kind=\"hist\",bins=100, logy=True, xlim=(0,.4),title=\"Outlier Fruit Juice prices by contributor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "Largest outliers in fruit juices seem to be from one contributor who has been submitting the same picture of a damaged can of fruit juice at various angles over the past 2 years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\n",
    "    i)  \n",
    "        Contributor\n",
    "        Location:\n",
    "        Variations in set of products\n",
    "    ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. i. For the data set, describe some variables that could be sources of sampling bias when estimating price trends in Ghana. Explain why each of these variables could cause sampling bias.\n",
    "\n",
    "#### ii. Pick one bias (not u_uuid). Write some code that attempts to estimate the potential amount of sample bias caused by this variable, and describe your methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotTrend(frame=None, y=\"\", product=\"\",grp=None):\n",
    "    grouped = frame.groupby([\"p_item_product_lc\"])\n",
    "    prod = grouped.get_group(\"%s\" % product) \n",
    "    #outlierProd = outliers[outliers[\"p_item_product_lc\"]==product]\n",
    "    #cleanedProd = prod.drop(outlierProd.index)\n",
    "    prod.loc[:,\"date\"]= prod[\"t_time\"].apply(lambda x : datetime.strptime(x.split(\".\")[0],\"%Y-%m-%d %X\").date())\n",
    "    avgCC = prod.groupby([\"date\"]).mean()\n",
    "    #display(avgCC)\n",
    "\n",
    "    if grp is not None:\n",
    "        for x in prod.groupby(grp):\n",
    "            if len(x[1].groupby([\"date\"]))> 1.0:\n",
    "                height = x[1][y].max() - x[1][y].min()\n",
    "                print x[1].groupby([\"date\"]).mean().plot( y = \"%s\" % y, title=\"%s Bar Prices (%s)\" % (product,x[0]), ylim =(prod[y].min()-5*height,prod[y].max()+5*height))\n",
    "    else:\n",
    "        height = prod[y].max() - prod[y].min()\n",
    "        print prod.plot(x=\"date\",y=\"%s\" % y, title=\"%s Prices (%s)\" % (product,y), ylim =(prod[y].min()-5*height,prod[y].max()+5*height))\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to look at the composition of the sample. i.e..sample by sample is a specific product over/under represented relative to other products.  For example, if normally, one expects on any given day that Coca-Cola bottles make up for 5% of submissions but yet for a specific day they made up 15% of the observations (maybe because contributors did not submit other products as much), then we can expect a bias in our sample.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add date column to dataframe\n",
    "def addDate(dFrame):\n",
    "    dFrame.loc[:,\"date\"]= dFrame[\"t_time\"].apply(lambda x : datetime.strptime(x.split(\".\")[0],\"%Y-%m-%d %X\").date())\n",
    "    return dFrame\n",
    "#remove outliers from dataframe\n",
    "df = addDate(df.drop(outliers.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the average daily price of each product for every purchase location for every city.\n",
    "\n",
    "Keep in mind that that we need the additional requirement that all fields be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newDf = pd.DataFrame()\n",
    "groups = [\"p_item_product_lc\",\"city\",\"l_place_name\",\"date\"]\n",
    "df = df.dropna(subset = groups)\n",
    "\n",
    "#test=df[df[\"p_item_product_lc\"]==\"Banana\"]\n",
    "#display(test[test[\"date\"]<datetime(2014, 11, 20).date()][groups])\n",
    "\n",
    "prodCityPlaceDateGrouped = df.groupby(groups, as_index=True)\n",
    "prodCityPlaceDate = prodCityPlaceDateGrouped[\"normalized_price\"].agg([np.mean])\n",
    "prodCityPlaceDate = prodCityPlaceDate.reset_index()\n",
    "#test=prodCityPlaceDate[prodCityPlaceDate[\"p_item_product_lc\"]==\"Banana\"]\n",
    "#display(test[test[\"date\"]<datetime(2014, 11, 20).date()])\n",
    "\n",
    "#prodCityPlaceDate[\"normalized_price\"][\"mean\"]\n",
    "#prodDateGrouped = prodCityPlaceDate.groupby([\"city\",\"l_place_name\"])\n",
    "prodDateGrouped = prodCityPlaceDate.groupby([\"p_item_product_lc\",\"date\"])\n",
    "unbiased = prodDateGrouped[\"mean\"].agg([np.mean])\n",
    "\n",
    "biasedGrouped = df.groupby([\"p_item_product_lc\",\"date\"], as_index=True)\n",
    "biased = biasedGrouped[\"normalized_price\"].agg([np.mean])\n",
    "unbiased = unbiased.reset_index()\n",
    "biased = biased.reset_index()\n",
    "#unbiased.sort_values(by=\"date\")\n",
    "#display(unbiased.head())\n",
    "#display(biased.head())\n",
    "#plotTrend(frame=unbiased,y=\"mean\",product=\"Banana\")\n",
    "\n",
    "def estimateBias(unbiased=None, biased=None):\n",
    "    biases = [] \n",
    "    unbiased[\"bias_est\"] = (unbiased[\"mean\"]-biased[\"mean\"])/ biased[\"mean\"]\n",
    "    for prod,prodDf in unbiased.groupby([\"p_item_product_lc\"]):\n",
    "        days = [(e - min(prodDf[\"date\"])).days for e in prodDf[\"date\"]] \n",
    "        l = linregress(days,prodDf[\"bias_est\"])\n",
    "        biases.append(np.abs(l.intercept))\n",
    "    return biases\n",
    "\n",
    "maxB = max(estimateBias(unbiased, biased))\n",
    "meanB = np.mean(estimateBias(unbiased, biased))\n",
    "print \"Average Bias in products due to imbalance sampling: %3.2f %%\" % meanB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelling Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Create a model that predicts price from various metadata.\n",
    "\n",
    "#### i. Explain how your model works, and why you chose it.\n",
    "\n",
    "I have decided to use a random forest regression. A random forest averages over a number of decision trees (where each splitting branch is a feature of our model) trained on different sub-sets of the dataset. \n",
    "\n",
    "Decision Trees are able to pick out subtle features in the data (i.e. difference prices of onions bought at supermarkets vs open-markets) at the expense of potentially over-fitting the data. Creating a random selection of tress (a forest) helps to control over-fitting. Averaging over these threes also improves the predictive accuracy.\n",
    "\n",
    "#### ii. Why did you use the metadata you used?\n",
    "\n",
    "I used :\n",
    "   * product: Not much to say there...can't compare apples and oranges...I need the product as a feature.\n",
    "   * city: I expect variations in price in Metropolitan vs rural cities for many products. \n",
    "   * location: SuperMarkets and open markets will most likely offer differing product, but also at different prices.   \n",
    "   * date: Using dates may allow our model to do some crude price forcasting (if time permits, I may try this.)\n",
    "\n",
    "I did not use:\n",
    "* package size, quantity, units: Since I'm predicting normalized price, those features are inheritly included.\n",
    "* Product brand: I don't have a strong reason to not have included this, although I think the dimensionality of the dataset could increase too much for my model to handle, or it may expose it to over-fitting.  I'll come back to this and include if I have time.\n",
    "   \n",
    "#### iii. How can you be sure that youâ€™re not overÂ­fitting the model?\n",
    "\n",
    "I split my dataset into 2/3 and 1/3 parts. The larger part is my training set while the latter is my testing set.\n",
    "As epected the model gives a 100% accuracy on my training set ( a sign of potential over-fitting) but it is able to accuratly predict 92 percent of my testing set, which is pretty good. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sort by date \n",
    "prodCityPlaceDate = prodCityPlaceDate.sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Isolate predictor variables\n",
    "X = prodCityPlaceDate.loc[:,groups]\n",
    "\n",
    "#Transform categorical labels into integers\n",
    "for group in groups:\n",
    "        X.loc[:,group] = LabelEncoder().fit_transform(X.loc[:,group])\n",
    "\n",
    "#Split dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,prodCityPlaceDate[\"mean\"], test_size=0.33, random_state=42)\n",
    "\n",
    "#instantiate model \n",
    "rfr = RandomForestRegressor(n_estimators=100, bootstrap=False)\n",
    "\n",
    "#fit\n",
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-39d84eba35bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#TestDf = prodCityPlaceDate[prodCityPlaceDate[\"date\"]>=datetime(2015, 3, 17).date()]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprodCityPlaceDate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mTrainDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msortedNewDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msortedNewDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2015\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rfr' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#TrainDf = prodCityPlaceDate[prodCityPlaceDate[\"date\"]<datetime(2015, 3, 17).date()]\n",
    "#TestDf = prodCityPlaceDate[prodCityPlaceDate[\"date\"]>=datetime(2015, 3, 17).date()]\n",
    "\n",
    "scores = cross_val_score(rfr,X,prodCityPlaceDate[\"mean\"], scoring='accuracy', cv=10)\n",
    "\n",
    "TrainDf = sortedNewDF[sortedNewDF[\"date\"]<datetime(2015, 3, 17).date()]\n",
    "TestDf = sortedNewDF[sortedNewDF[\"date\"]>=datetime(2015, 3, 17).date()]\n",
    "\n",
    "\n",
    "for t in TrainDf.groupby([\"p_item_product_lc\"]):\n",
    "    print t[0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
