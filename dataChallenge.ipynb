{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from scipy.stats import lognorm, zscore\n",
    "%matplotlib inline \n",
    "from IPython.display import display\n",
    "from datetime import datetime \n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy.stats import linregress\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.preprocessing import LabelEncoder  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 9\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('crap.csv', header=0)\n",
    "pd.set_option('display.max_colwidth', 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Outlier Detection\n",
    "   Two cases come to mind:\n",
    "       a) An input error by the contributor. This may an incorrect placement of a decimal point (i.e. quantity=1.00 -> quantity=100.).  The mistake can happen while inputing the price, quantity, size, units. Each of these contribute to the normalized price which will we use to find the outliers. \n",
    "       b) Given that contributors are financially compensated for the contributions, fraudulent submissions are innevitble. This often leads to a cat-and-mouse situation and the outlier algorithm needs to be updated\n",
    "       \n",
    "1.2 Not quite guassian Log-Normal plot(?):\n",
    "    Giving that we do not expect prices to go below 0 and that decimal point mistakes can change the price values by order of magnitudes above and below the real price, a guassian distribution may not be suitable to model prices. On the otherhand, the log of the prices could follow a normal distributions so we use that.     \n",
    "    \n",
    "1.3 Method:\n",
    "    After transforming the normalized price column to Log(normalized price), we define an outlier as a data point likes beyond 3 sigma of the mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Empty dataframe to fill later\n",
    "outliers = pd.DataFrame()\n",
    "\n",
    "#Create dataframes who's content has ben grouped by Product\n",
    "#groupedDf = df.groupby([\"p_item_product_lc\",\"city\"])\n",
    "groupedDf = df.groupby([\"p_item_product_lc\"])\n",
    "\n",
    "\n",
    "for prod_place, gp in groupedDf:\n",
    "    #Add column of Log(normalized prices)\n",
    "    gp.loc[:,'log_normalized_price'] = gp['normalized_price'].apply(lambda x: np.log(x))\n",
    "    \n",
    "    #Calculate z-score\n",
    "    gp.loc[:,'zScore']= zscore(gp['log_normalized_price'])\n",
    "    \n",
    "    #store datapoints at least 1.96 sigma away\n",
    "    #z = gp.loc[gp[\"zScore\"]>9.96].loc[:,[\"p_item_product_lc\",\"normalized_price\", \"zScore\",\"city\",\"l_place_name\",\"u_uuid\",\"t_time\"]]\n",
    "    z = gp[np.abs(gp[\"zScore\"])>1.96]\n",
    "\n",
    "    if not z.empty : \n",
    "        outliers = outliers.append(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#display all outliers by product\n",
    "display(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed many Fruit Juice observations have a z score above ten.  Investingating a bit more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fruitJuice = df[df[\"p_item_product_lc\"]==\"Fruit juice\"]\n",
    "\n",
    "fruitJuice.ix[:,\"normalized_price\"].plot(kind=\"hist\",bins=100, logy=True, title=\"Fruit Juice Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fruitJuiceOutliers= outliers[outliers[\"p_item_product_lc\"]==\"Fruit juice\"]\n",
    "for contributor in fruitJuiceOutliers.groupby(\"u_uuid\"):\n",
    "    contributor[1].loc[:,\"normalized_price\"].plot(kind=\"hist\",bins=100, logy=True, xlim=(0,.4),title=\"Outlier Fruit Juice prices by contributor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "Largest outliers in fruit juices seem to be from one contributor who has been submitting the same picture of a damaged can of fruit juice at various angles over the past 2 years. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\n",
    "    i)  \n",
    "        Contributor\n",
    "        Location:\n",
    "        Variations in set of products\n",
    "    ii)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotTrend(frame=None, y=\"\", product=\"\",grp=None):\n",
    "    grouped = frame.groupby([\"p_item_product_lc\"])\n",
    "    prod = grouped.get_group(\"%s\" % product) \n",
    "    #outlierProd = outliers[outliers[\"p_item_product_lc\"]==product]\n",
    "    #cleanedProd = prod.drop(outlierProd.index)\n",
    "    prod.loc[:,\"date\"]= prod[\"t_time\"].apply(lambda x : datetime.strptime(x.split(\".\")[0],\"%Y-%m-%d %X\").date())\n",
    "    avgCC = prod.groupby([\"date\"]).mean()\n",
    "    #display(avgCC)\n",
    "\n",
    "    if grp is not None:\n",
    "        for x in prod.groupby(grp):\n",
    "            if len(x[1].groupby([\"date\"]))> 1.0:\n",
    "                height = x[1][y].max() - x[1][y].min()\n",
    "                print x[1].groupby([\"date\"]).mean().plot( y = \"%s\" % y, title=\"%s Bar Prices (%s)\" % (product,x[0]), ylim =(prod[y].min()-5*height,prod[y].max()+5*height))\n",
    "    else:\n",
    "        height = prod[y].max() - prod[y].min()\n",
    "        print prod.plot(x=\"date\",y=\"%s\" % y, title=\"%s Prices (%s)\" % (product,y), ylim =(prod[y].min()-5*height,prod[y].max()+5*height))\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to look at the composition of the sample. i.e..sample by sample is a specific product over/under represented relative to other products.  For example, if normally, one expects on any given day that Coca-Cola bottles make up for 5% of submissions but yet for a specific day they made up 15% of the observations (maybe because contributors did not submit other products as much), then we can expect a bias in our sample.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) This question is pretty open ended (probably purposefully).  Price prediction at what level? An apple in a supermarket? any apple in a Accra? Or apples Ghana?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addDate(dFrame):\n",
    "    dFrame.loc[:,\"date\"]= dFrame[\"t_time\"].apply(lambda x : datetime.strptime(x.split(\".\")[0],\"%Y-%m-%d %X\").date())\n",
    "    return dFrame\n",
    "df = addDate(df.drop(outliers.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the average daily price of each product for every purchase location for every city.\n",
    "\n",
    "Keep in mind that that we need the additional requirement that all fields be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.086506281188178283"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDf = pd.DataFrame()\n",
    "groups = [\"p_item_product_lc\",\"city\",\"l_place_name\",\"date\"]\n",
    "df = df.dropna(subset = groups)\n",
    "\n",
    "#test=df[df[\"p_item_product_lc\"]==\"Banana\"]\n",
    "#display(test[test[\"date\"]<datetime(2014, 11, 20).date()][groups])\n",
    "\n",
    "prodCityPlaceDateGrouped = df.groupby(groups, as_index=True)\n",
    "prodCityPlaceDate = prodCityPlaceDateGrouped[\"normalized_price\"].agg([np.mean])\n",
    "prodCityPlaceDate = prodCityPlaceDate.reset_index()\n",
    "#test=prodCityPlaceDate[prodCityPlaceDate[\"p_item_product_lc\"]==\"Banana\"]\n",
    "#display(test[test[\"date\"]<datetime(2014, 11, 20).date()])\n",
    "\n",
    "#prodCityPlaceDate[\"normalized_price\"][\"mean\"]\n",
    "#prodDateGrouped = prodCityPlaceDate.groupby([\"city\",\"l_place_name\"])\n",
    "prodDateGrouped = prodCityPlaceDate.groupby([\"p_item_product_lc\",\"date\"])\n",
    "unbiased = prodDateGrouped[\"mean\"].agg([np.mean])\n",
    "\n",
    "biasedGrouped = df.groupby([\"p_item_product_lc\",\"date\"], as_index=True)\n",
    "biased = biasedGrouped[\"normalized_price\"].agg([np.mean])\n",
    "unbiased = unbiased.reset_index()\n",
    "biased = biased.reset_index()\n",
    "#unbiased.sort_values(by=\"date\")\n",
    "#display(unbiased.head())\n",
    "#display(biased.head())\n",
    "#plotTrend(frame=unbiased,y=\"mean\",product=\"Banana\")\n",
    "\n",
    "def estimateBias(unbiased=None, biased=None):\n",
    "    biases = [] \n",
    "    unbiased[\"bias_est\"] = (unbiased[\"mean\"]-biased[\"mean\"])/ biased[\"mean\"]\n",
    "    for prod,prodDf in unbiased.groupby([\"p_item_product_lc\"]):\n",
    "        days = [(e - min(prodDf[\"date\"])).days for e in prodDf[\"date\"]] \n",
    "        l = linregress(days,prodDf[\"bias_est\"])\n",
    "        biases.append(l.intercept)\n",
    "    return biases\n",
    "\n",
    "max(estimateBias(unbiased, biased))\n",
    "#prodDateGrouped[\"mean\"].agg([np.mean])\n",
    "#prodDate = prodDateGrouped[\"normalized_price\"][\"mean\"].agg([np.mean])\n",
    "\n",
    "#[\"normalized_price\"][\"mean\"]\n",
    "# test\n",
    "#test2= test.groupby(level=2)\n",
    "#test3 = test2[\"mean\"].agg([np.mean])\n",
    "#for name, prodCityPlace in grouped:\n",
    "#    if len(prodCityPlace)>10:\n",
    "#        \n",
    "#        #prodCityPlace[\"dailyAvg_normalized_price\"] = prodCityPlace[\"normalized_price\"].mean() \n",
    "#        newDf = newDf.append(prodCityPlace.iloc[:1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelling Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) This question is pretty open ended (probably purposefully). Price prediction at what level? An apple in a supermarket? any apple in a Accra? Or apples Ghana?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unbiased\n",
    "prodCityPlaceDate.sort_values(by=groups)\n",
    "\n",
    "X = prodCityPlaceDate.loc[:,groups]\n",
    "for group in groups:\n",
    "        X.loc[:,group] = LabelEncoder().fit_transform(X.loc[:,group])\n",
    "        \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,prodCityPlaceDate[\"mean\"], test_size=0.33, random_state=42)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "\n",
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99372651171970405"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_train[:100],y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333589864075843"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test[:100],y_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#TrainDf = prodCityPlaceDate[prodCityPlaceDate[\"date\"]<datetime(2015, 3, 17).date()]\n",
    "#TestDf = prodCityPlaceDate[prodCityPlaceDate[\"date\"]>=datetime(2015, 3, 17).date()]\n",
    "\n",
    "\n",
    "TrainDf = sortedNewDF[sortedNewDF[\"date\"]<datetime(2015, 3, 17).date()]\n",
    "TestDf = sortedNewDF[sortedNewDF[\"date\"]>=datetime(2015, 3, 17).date()]\n",
    "\n",
    "\n",
    "for t in TrainDf.groupby([\"p_item_product_lc\"]):\n",
    "    print t[0]\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
